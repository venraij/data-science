{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection and description\n",
    "\n",
    "### Leerdoelen 2. data exploratie & visualisatie\n",
    "- Je leert welke onderdelen in een goede Data Understanding thuis horen.\n",
    "- Je gaat zelf een rapport maken waar een goede Data Understanding in zit. \n",
    "- Je kan met Pandas data inlezen en bewerken. \n",
    "- Je kan met Seaborn of matplotlib visualisaties maken van de data. \n",
    "\n",
    "### Achtergrondinformatie werkcollege 1:\n",
    "- Google naar \n",
    "    - `pandas read csv file`\n",
    "- Datacamp course `Manipulating data with Pandas`\n",
    "\n",
    "### Achtergrondinformatie werkcollege 1:\n",
    "- Google naar \n",
    "    - `pandas dataframe make histogram`\n",
    "    - `pandas correlation`\n",
    "    - `seaborn correlation plot`\n",
    "    - `seaborn pair plot`\n",
    "    - `pandas dataframe plot variables`\n",
    "- Datacamp course `Introduction to Data Visualisation with Python` en eventueel `Data Visualization with Seaborn`. \n",
    "\n",
    "### Opdracht \n",
    "- Maak een Data Understanding hoofdstuk voor de gegeven KNMI dataset, gemodelleerd naar het voorbeeld wat je gekregen hebt. De data is een bewerkte versie van data gedownload van [deze link](http://projects.knmi.nl/klimatologie/daggegevens/selectie.cgi). \n",
    "- Leg uit (Trace&Explain) wat de code in `read_knmi_data` doet in elk van de stappen. \n",
    "- Als je een beeld van de data hebt, probeer iets te zeggen over het soort Business understanding wat je zou kunnen krijgen met deze data. \n",
    "- Data prepation, Modeling en Evaluation hoef je deze week niet aan te vullen. \n",
    "\n",
    "# Business understanding\n",
    "Voor klimaatwetenschappers is het van groot belang om de ontwikkeling van het klimaat te volgen. Echte metingen kunnen trends laten zien, bijvoorbeeld een toename in het aantal extreme regenbuien. Een toename hiervan zou bijvoorbeeld gevolgen kunnen hebben voor de hoogte van de grote rivieren, en dus voor de benodigde hoogte van de dijken. \n",
    "\n",
    "De volgende dataset laat wat klimaatgegevens zien over de tijd. \n",
    "\n",
    "# Data Understanding\n",
    "De data staat in een tekst bestand (.txt), maar na het openen van het bestand in een tekst editor is het duidelijk dat dit een csv bestand is. De functie `read_knmi_data` leest de knmi datafile in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instellingen aanpassen\n",
    "Als je gewend bent aan andere ontwikkelomgevingen dan heb je bijv. gemist dat de beschikbare objecten getoond worden en dat je deze automatisch kunt aanvullen. Hiervoor stellen we de completer in op 'greedy' m.b.v. zogenaamde Jupyter Notebook Magic. \n",
    "\n",
    "Om later ook de visualisaties in het Notebook te tonen zorgen we dat de output van het package matplotlib ook als (inline) output wordt getoond in het Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handige jupyter notebook magic\n",
    "%config IPCompleter.greedy = True  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial data collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De data in het tekst-bestand is een csv-bestand. We kunnen dit direct inlezen als csv-bestand in het Notebook.\n",
    "\n",
    "Hiervoor maken we gebruik van de read_csv methode in pandas. \n",
    "- de file moet je altijd meegeven\n",
    "- de separator is ook handig om expliciet aan te geven. Doe je dit niet, dan wordt een komma gebruikt.\n",
    "- In dit tekstbestand staat de toelichting op de variabelen als commentaar. Deze regels moeten worden genegeerd bij het inlezen van de gegevens. Dit doen we door dit mee te geven als argument in de methode.\n",
    "- De kolomnamen staan ook als commentaar aangegeven. We hebben hier twee mogelijke werkwijzen: 1) het bronbestand aanpassen door voor deze regel het commmentaar aan te passen. Nadeel: het is dan later niet navolgbaar wat er is aangepast in de aangeleverde data. We kiezen voor 2) de gegevens inlezen zonder de header van het csv-bestand. Daarna geven we de kolommen in ons DataFrame begrijpbare namen. \n",
    "\n",
    "**Opdracht: We moeten één van onderstaande manieren kiezen om de gegevens te importeren. Welke vinden jullie het geschiktst? Licht je antwoord toe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas importeren in onze werkomgeving\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data files\n",
    "data_source='knmi_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 14, saw 6\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5088\\849648044.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mknmi_data_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 14, saw 6\n"
     ]
    }
   ],
   "source": [
    "knmi_data_1=pd.read_csv(data_source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit werkt niet omdat er comments aanwezig zijn. De character van de comments moet aangegeven worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knmi_data_2=pd.read_csv(data_source,comment='#', header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit kan maar dan zit je nog wel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_dates: Let pandas try and transform this column to a date\n",
    "knmi_data_3=pd.read_csv(data_source,sep=',', comment='#', header=None, parse_dates=[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is beter want nu kan je ook gelijk nuttiger gebruik maken van de data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knmi_data_4=pd.read_csv(data_source,sep=',', comment='#', header=None, names=['station', 'datum', 'T_gem', 'T_min', 'T_max', 'Neerslag'], parse_dates=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knmi_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5088\\2566229586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mknmi_data_4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknmi_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'station'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'datum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'knmi_data' is not defined"
     ]
    }
   ],
   "source": [
    "knmi_data_4=knmi_data.set_index(['station','datum'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit werkt niet want knmi_data wordt nooit gedefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_knmi_data(filename, names):\n",
    "    return pd.read_csv(filename, \n",
    "                       comment='#',               # Skip all comments\n",
    "                       header=None,               # No header\n",
    "                       names=names,\n",
    "                       skipinitialspace=True,     # Fix the trailing spaces after the ','-separator\n",
    "                       index_col=[0,1],           # Use the first two columns as the row index\n",
    "                       parse_dates=[1])           # Let pandas try and transform the second column to a date\n",
    "\n",
    "knmi_data_5 = read_knmi_data(data_source, names=['station', 'datum', 'T_gem', 'T_min', 'T_max', 'Neerslag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[plaats hier je feedback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Onderbouw het alternatief dat jullie kiezen. Kopieer deze code en importeer de gegevens in onze werkomgeving als DataFrame knmi_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "\n",
    "In de data zien we de volgende variabelen:\n",
    "\n",
    "- T_gem, gemiddelde temperatuur per dag\n",
    "- T_min, de minimum temperatuur per dag\n",
    "- T_max, de maximum temperatuur per dag\n",
    "- Neerslag, de hoeveelheid neerslag per dag\n",
    "- station, het stations id (in de index)\n",
    "- datum, de datum (in de index)\n",
    "\n",
    "Als we wat verder in de data duiken:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voer alle stappen uit die nodig zijn om:** \n",
    "\n",
    "*Describe the data that has been acquired, including the format of the data, the quantity of data (for example, the number of records and fields in each table), the identities of the fields, and any other surface features which have been discovered. Evaluate whether the data acquired satisfies the relevant requirements.* \n",
    "(bron: CRISP-DM1.0, p.18)\n",
    "\n",
    "Om dit voor elkaar te krijgen moet je een keuze maken uit de volgende tools:\n",
    "- Het aantal rijen in de data\n",
    "- Het aantal kolommen in de data\n",
    "- Een overzicht van het aantal missende waardes per kolom\n",
    "- Een lijst met de kolomnamen van de data\n",
    "- Een overzicht met informatie over de data\n",
    "- Een lijst met het datatype per kolom in de data\n",
    "\n",
    "**Opdracht:** Zoek voor elk van deze opties de bijbehorende Pandas code. Kies daarna een aantal van deze tools uit om je data mee te beschrijven. Welke kies je en waarom? Wat voor conclusies trek je uit de uitkomst? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoeveelheid rows kort en makkelijk weergeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3656"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knmi_data_5.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3656"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knmi_data_5.count()[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataexploration\n",
    "## Statistische samenvatting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we de data ingelezen hebben, en de oppervlaktekenmerken beschreven hebben willen we meer de inhoud van de data induiken. \n",
    "\n",
    "\n",
    "Om dit voor elkaar te krijgen moet je een keuze maken uit de volgende tools:\n",
    "- Een aantal basisstatistieken per kolom\n",
    "- De eerste paar rijen van de data\n",
    "- (alleen voor tijdsseries) hoeveel tijd beslaat de data\n",
    "\n",
    "**Opdracht:** Zoek voor elk van deze opties de bijbehorende Pandas code. Kies daarna een aantal van deze tools uit om je data mee te beschrijven. Welke kies je en waarom? Wat voor conclusies trek je uit de uitkomst? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafische exploratie\n",
    "Na de statistische samenvatting willen we een aantal slimme visualisaties inzetten om nog verder de data te verkennen. \n",
    "\n",
    "Om dit voor elkaar te krijgen moet je een keuze maken uit de volgende tools:\n",
    "- Een histogram per kolom in de data\n",
    "- Een heatmap die de correlatie laat zien tussen alle kolommen in de data\n",
    "- Een pairplot wat scatterplots laat zien tussen alle kolommen in de data\n",
    "- Een tijdsserieplot wat de ontwikkeling in de tijd laat zien per kolom in de data\n",
    "\n",
    "**Opdracht:** Zoek voor elk van deze opties de bijbehorende Pandas code. Kies daarna een aantal van deze tools uit om je data mee te beschrijven. Welke kies je en waarom? Wat voor conclusies trek je uit de uitkomst? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "Een aantal bewerkingsstappen komen voort uit de Data Understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knmi_data[['T_gem', 'T_min', 'T_max']] = knmi_data[['T_gem', 'T_min', 'T_max']] / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Een regressie model tussen neerslag en temperatuur laat geen verband zien, en ook geen verloop in de tijd. \n",
    "\n",
    "# Evaluation\n",
    "Op deze korte dataset van 1 station is er geen duidelijke shift te zien in patronen. Ons vermoeden is dat de huidige dataset simpelweg te beperkt is om een trend te spotten. We zullen terug naar de klant moeten om meer data te verzamelen. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
